{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Beginning Work on Twitter Disaster Kaggle Competition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "# from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "# from tensorflow.keras import backend as K\n",
    "# ## for bert language model\n",
    "# import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we will define a function that takes in a column with raw text data and returns a cleaned version of that column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"..\\\\data\\\\test.csv\")\n",
    "test = pd.read_csv(\"..\\\\data\\\\train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Things to notice is that the size of our dataframe is 3263 but there are only 3237 non-null values and 2158 for keyword and location respectively"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n       'fire', 'fire%20truck', 'first%20responders', 'flames',\n       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.unique() # notice NaN is a keyword"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([nan, 'London', \"Niall's place | SAF 12 SQUAD |\", ...,\n       'Acey mountain islanddåÇTorontoåÈ', 'los angeles',\n       'Brussels, Belgium'], dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.location.unique() # again here NaN is a location"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eventually we will need to figure out what to do with these missing values, but for now lets focus on cleaning up the text!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([    0,     2,     3, ..., 10868, 10874, 10875], dtype=int64)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.id.unique() # no repeating ids which is good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'keyword', 'location', 'text'], dtype='object')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Found a list of contractions from a stack overflow post. This dictionary will be used to convert contractions to their root words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = {\n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This function will be used to do 4 things at once:\n",
    " 1) it will turn any contractions that appear above into their respected root words i.e \"won't\" will become \"will not\"\n",
    "\n",
    "2) It will use a regular expression to remove any unwanted characters from our text. In this case unwanted characters are punctuation and any special characters sucha as '@'\n",
    "\n",
    "3) It will remove any stop words that appear in our text. Here the stop words were pulled from a pre-defined list of stopwords from NLTK\n",
    "\n",
    "4) Lastly it will tokenize our text. Tokenization is the process of taking a body of text and converting it into lists of strings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "\n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace contractions with their longer forms\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\")) # pulli-ng a list of stopwords from NLTK\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train['text_cleaned'] = list(map(clean_text, train.text))\n",
    "test['text_cleaned'] = list(map(clean_text, test.text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lemmatizing is the process of taking a word like swimming and converting it to its dictionary root word. So swimming becomes swim, eating becomes eat. Swam becomes swim. For more information click here:\n",
    "https://towardsdatascience.com/lemmatization-in-natural-language-processing-nlp-and-machine-learning-a4416f69a7b6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def lemmatized_words(df):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    df['lemmatized_text'] = list(map(lambda word:\n",
    "                                     list(map(lemm.lemmatize, word)),\n",
    "                                     df.text_cleaned))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "lemmatized_words(train)\n",
    "lemmatized_words(test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train[\"text_str\"]=train[\"lemmatized_text\"].apply(lambda x: \" \".join(x) )\n",
    "test[\"text_str\"]=test[\"lemmatized_text\"].apply(lambda x: \" \".join(x) )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   0     NaN      NaN                 Just happened a terrible car crash   \n1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n\n                                        text_cleaned  \\\n0                   [happened, terrible, car, crash]   \n1  [heard, earthquake, different, cities, stay, s...   \n2  [forest, fire, spot, pond, geese, fleeing, acr...   \n3         [apocalypse, lighting, spokane, wildfires]   \n4      [typhoon, soudelor, kills, 28, china, taiwan]   \n\n                                     lemmatized_text  \\\n0                   [happened, terrible, car, crash]   \n1  [heard, earthquake, different, city, stay, saf...   \n2  [forest, fire, spot, pond, goose, fleeing, acr...   \n3          [apocalypse, lighting, spokane, wildfire]   \n4       [typhoon, soudelor, kill, 28, china, taiwan]   \n\n                                            text_str  \n0                        happened terrible car crash  \n1  heard earthquake different city stay safe ever...  \n2  forest fire spot pond goose fleeing across str...  \n3               apocalypse lighting spokane wildfire  \n4              typhoon soudelor kill 28 china taiwan  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>text_cleaned</th>\n      <th>lemmatized_text</th>\n      <th>text_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n      <td>[happened, terrible, car, crash]</td>\n      <td>[happened, terrible, car, crash]</td>\n      <td>happened terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n      <td>[heard, earthquake, different, cities, stay, s...</td>\n      <td>[heard, earthquake, different, city, stay, saf...</td>\n      <td>heard earthquake different city stay safe ever...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n      <td>[forest, fire, spot, pond, geese, fleeing, acr...</td>\n      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n      <td>forest fire spot pond goose fleeing across str...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n      <td>[apocalypse, lighting, spokane, wildfires]</td>\n      <td>[apocalypse, lighting, spokane, wildfire]</td>\n      <td>apocalypse lighting spokane wildfire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n      <td>[typhoon, soudelor, kills, 28, china, taiwan]</td>\n      <td>[typhoon, soudelor, kill, 28, china, taiwan]</td>\n      <td>typhoon soudelor kill 28 china taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()  #ntoice our new dataframe has two new columns text_cleaned and lemmatized_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        id            keyword                        location  \\\n231    750          avalanche                             NaN   \n290    937              blaze                   Cleveland, OH   \n344   1115          blew%20up                    Coos Bay, OR   \n353   1140             blight                             NaN   \n377   1210           blizzard                      That place   \n411   1330         blown%20up                     Scout Team    \n414   1339         blown%20up              somewhere or other   \n481   1564               bomb                        shanghai   \n584   1902            burning                  daily ? 18 ? ?   \n666   2168       catastrophic                             NaN   \n704   2291       cliff%20fall                             NaN   \n826   2716            crushed                      Motown, WV   \n846   2779             curfew        770 to Benedict College    \n878   2897             damage                 California, USA   \n1018  3348         demolished                     Connecticut   \n1020  3350         demolished                             NaN   \n1432  4743           evacuate                       San Diego   \n1451  4815         evacuation                             NaN   \n1482  4932           exploded                             NaN   \n1576  5318               fire                             NaN   \n1629  5483             flames                     Little Rock   \n1804  6095           hellfire                             NaN   \n2190  7333  nuclear%20reactor                             NaN   \n2552  8521          screaming         HYPE RESSHA HYPE RESSHA   \n2956  9793            trapped                     Houston, TX   \n2961  9804            trapped                         Orlando   \n3018  9966            tsunami  rest easy angel @datboiiharri.   \n\n                                                   text  \\\n231   if this fucking is true i will be decapitated ...   \n290   I never got paid to give a fuck..we might as w...   \n344   We were fucking around on Google maps at work ...   \n353                 @colemcfadyean fuck off cole ??????   \n377   If blizzard did another 12 month sub thing and...   \n411   If you bored as shit don't nobody fuck wit you...   \n414   I don't understand how White Iverson by Post M...   \n481      Bruh this sex on the beach??is bomb as fuck yo   \n584   RT: A real burn book entry about CA: why the f...   \n666   If a å£1 rise in wages is going to have such a...   \n704   @JohnnieGuilbert jump off a cliff. I'll be che...   \n826   So in one episode they undo season 1. Kai join...   \n846   everybody like fuck curfew.. and i'm sitting h...   \n878                Got my first damage today  fuckkkkkk   \n1018                   That ball was fucking demolished   \n1020  @who_mikejoness I hate seeing the boy get fuck...   \n1432  my father fucking died when the north tower co...   \n1451  my school is so fucking dumb they just set off...   \n1482  Our electricity just fucking exploded they're ...   \n1576  almost set the house on fire tryna make fuckin...   \n1629           I only fuck you when it's half past five   \n1804  I'm melting a bar of chocolate under my laptop...   \n2190  they're gonna fucking steal a nuclear fission ...   \n2552       i'm fucking screaming http://t.co/H3MrqRrGfe   \n2956  If I ever saw a dog trapped in a hot car you b...   \n2961  It's a trap not a fucking game. U ain't trappi...   \n3018  I just wanna food but of course I had to get c...   \n\n                                           text_cleaned  \\\n231   [fucking, true, decapitated, throw, head, aval...   \n290   [never, got, paid, give, fuck, might, well, bl...   \n344   [fucking, around, google, maps, work, pulled, ...   \n353                         [colemcfadyean, fuck, cole]   \n377   [blizzard, another, 12, month, sub, thing, gav...   \n411   [bored, shit, nobody, fuck, wit, busy, yo, shi...   \n414   [understand, white, iverson, post, malone, blo...   \n481                  [bruh, sex, beach, bomb, fuck, yo]   \n584   [rt, real, burn, book, entry, ca, fuck, place,...   \n666   [å, £, 1, rise, wages, going, catastrophic, im...   \n704   [johnnieguilbert, jump, cliff, cheering, back,...   \n826   [one, episode, undo, season, 1, kai, joins, ff...   \n846   [everybody, like, fuck, curfew, sitting, like,...   \n878              [got, first, damage, today, fuckkkkkk]   \n1018                        [ball, fucking, demolished]   \n1020  [mikejoness, hate, seeing, boy, get, fucking, ...   \n1432  [father, fucking, died, north, tower, collapse...   \n1451  [school, fucking, dumb, set, evacuation, siren...   \n1482      [electricity, fucking, exploded, trying, fix]   \n1576  [almost, set, house, fire, tryna, make, fuckin...   \n1629                           [fuck, half, past, five]   \n1804  [melting, bar, chocolate, laptop, least, fucki...   \n2190  [gonna, fucking, steal, nuclear, fission, reac...   \n2552                               [fucking, screaming]   \n2956  [ever, saw, dog, trapped, hot, car, better, be...   \n2961     [trap, fucking, game, u, trapping, u, trapped]   \n3018  [wanna, food, course, get, caught, fucking, ts...   \n\n                                        lemmatized_text  \\\n231   [fucking, true, decapitated, throw, head, aval...   \n290   [never, got, paid, give, fuck, might, well, bl...   \n344   [fucking, around, google, map, work, pulled, b...   \n353                         [colemcfadyean, fuck, cole]   \n377   [blizzard, another, 12, month, sub, thing, gav...   \n411   [bored, shit, nobody, fuck, wit, busy, yo, shi...   \n414   [understand, white, iverson, post, malone, blo...   \n481                  [bruh, sex, beach, bomb, fuck, yo]   \n584   [rt, real, burn, book, entry, ca, fuck, place,...   \n666   [å, £, 1, rise, wage, going, catastrophic, imp...   \n704   [johnnieguilbert, jump, cliff, cheering, back,...   \n826   [one, episode, undo, season, 1, kai, join, ff,...   \n846   [everybody, like, fuck, curfew, sitting, like,...   \n878              [got, first, damage, today, fuckkkkkk]   \n1018                        [ball, fucking, demolished]   \n1020  [mikejoness, hate, seeing, boy, get, fucking, ...   \n1432  [father, fucking, died, north, tower, collapse...   \n1451  [school, fucking, dumb, set, evacuation, siren...   \n1482      [electricity, fucking, exploded, trying, fix]   \n1576  [almost, set, house, fire, tryna, make, fuckin...   \n1629                           [fuck, half, past, five]   \n1804  [melting, bar, chocolate, laptop, least, fucki...   \n2190  [gonna, fucking, steal, nuclear, fission, reac...   \n2552                               [fucking, screaming]   \n2956  [ever, saw, dog, trapped, hot, car, better, be...   \n2961     [trap, fucking, game, u, trapping, u, trapped]   \n3018  [wanna, food, course, get, caught, fucking, ts...   \n\n                                               text_str  \n231       fucking true decapitated throw head avalanche  \n290   never got paid give fuck might well blaze anot...  \n344   fucking around google map work pulled boise bl...  \n353                             colemcfadyean fuck cole  \n377   blizzard another 12 month sub thing gave next ...  \n411   bored shit nobody fuck wit busy yo shit get bl...  \n414   understand white iverson post malone blown fuc...  \n481                         bruh sex beach bomb fuck yo  \n584   rt real burn book entry ca fuck place always b...  \n666   å £ 1 rise wage going catastrophic impact wage...  \n704   johnnieguilbert jump cliff cheering back flip ...  \n826   one episode undo season 1 kai join ff ren beat...  \n846      everybody like fuck curfew sitting like bed 12  \n878                    got first damage today fuckkkkkk  \n1018                            ball fucking demolished  \n1020  mikejoness hate seeing boy get fucking demolis...  \n1432  father fucking died north tower collapsed tryi...  \n1451  school fucking dumb set evacuation siren accident  \n1482            electricity fucking exploded trying fix  \n1576    almost set house fire tryna make fucking hotdog  \n1629                                fuck half past five  \n1804  melting bar chocolate laptop least fucking hel...  \n2190        gonna fucking steal nuclear fission reactor  \n2552                                  fucking screaming  \n2956  ever saw dog trapped hot car better believe bu...  \n2961             trap fucking game u trapping u trapped  \n3018       wanna food course get caught fucking tsunami  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>text_cleaned</th>\n      <th>lemmatized_text</th>\n      <th>text_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>231</th>\n      <td>750</td>\n      <td>avalanche</td>\n      <td>NaN</td>\n      <td>if this fucking is true i will be decapitated ...</td>\n      <td>[fucking, true, decapitated, throw, head, aval...</td>\n      <td>[fucking, true, decapitated, throw, head, aval...</td>\n      <td>fucking true decapitated throw head avalanche</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>937</td>\n      <td>blaze</td>\n      <td>Cleveland, OH</td>\n      <td>I never got paid to give a fuck..we might as w...</td>\n      <td>[never, got, paid, give, fuck, might, well, bl...</td>\n      <td>[never, got, paid, give, fuck, might, well, bl...</td>\n      <td>never got paid give fuck might well blaze anot...</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>1115</td>\n      <td>blew%20up</td>\n      <td>Coos Bay, OR</td>\n      <td>We were fucking around on Google maps at work ...</td>\n      <td>[fucking, around, google, maps, work, pulled, ...</td>\n      <td>[fucking, around, google, map, work, pulled, b...</td>\n      <td>fucking around google map work pulled boise bl...</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>1140</td>\n      <td>blight</td>\n      <td>NaN</td>\n      <td>@colemcfadyean fuck off cole ??????</td>\n      <td>[colemcfadyean, fuck, cole]</td>\n      <td>[colemcfadyean, fuck, cole]</td>\n      <td>colemcfadyean fuck cole</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>1210</td>\n      <td>blizzard</td>\n      <td>That place</td>\n      <td>If blizzard did another 12 month sub thing and...</td>\n      <td>[blizzard, another, 12, month, sub, thing, gav...</td>\n      <td>[blizzard, another, 12, month, sub, thing, gav...</td>\n      <td>blizzard another 12 month sub thing gave next ...</td>\n    </tr>\n    <tr>\n      <th>411</th>\n      <td>1330</td>\n      <td>blown%20up</td>\n      <td>Scout Team</td>\n      <td>If you bored as shit don't nobody fuck wit you...</td>\n      <td>[bored, shit, nobody, fuck, wit, busy, yo, shi...</td>\n      <td>[bored, shit, nobody, fuck, wit, busy, yo, shi...</td>\n      <td>bored shit nobody fuck wit busy yo shit get bl...</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1339</td>\n      <td>blown%20up</td>\n      <td>somewhere or other</td>\n      <td>I don't understand how White Iverson by Post M...</td>\n      <td>[understand, white, iverson, post, malone, blo...</td>\n      <td>[understand, white, iverson, post, malone, blo...</td>\n      <td>understand white iverson post malone blown fuc...</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>1564</td>\n      <td>bomb</td>\n      <td>shanghai</td>\n      <td>Bruh this sex on the beach??is bomb as fuck yo</td>\n      <td>[bruh, sex, beach, bomb, fuck, yo]</td>\n      <td>[bruh, sex, beach, bomb, fuck, yo]</td>\n      <td>bruh sex beach bomb fuck yo</td>\n    </tr>\n    <tr>\n      <th>584</th>\n      <td>1902</td>\n      <td>burning</td>\n      <td>daily ? 18 ? ?</td>\n      <td>RT: A real burn book entry about CA: why the f...</td>\n      <td>[rt, real, burn, book, entry, ca, fuck, place,...</td>\n      <td>[rt, real, burn, book, entry, ca, fuck, place,...</td>\n      <td>rt real burn book entry ca fuck place always b...</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>2168</td>\n      <td>catastrophic</td>\n      <td>NaN</td>\n      <td>If a å£1 rise in wages is going to have such a...</td>\n      <td>[å, £, 1, rise, wages, going, catastrophic, im...</td>\n      <td>[å, £, 1, rise, wage, going, catastrophic, imp...</td>\n      <td>å £ 1 rise wage going catastrophic impact wage...</td>\n    </tr>\n    <tr>\n      <th>704</th>\n      <td>2291</td>\n      <td>cliff%20fall</td>\n      <td>NaN</td>\n      <td>@JohnnieGuilbert jump off a cliff. I'll be che...</td>\n      <td>[johnnieguilbert, jump, cliff, cheering, back,...</td>\n      <td>[johnnieguilbert, jump, cliff, cheering, back,...</td>\n      <td>johnnieguilbert jump cliff cheering back flip ...</td>\n    </tr>\n    <tr>\n      <th>826</th>\n      <td>2716</td>\n      <td>crushed</td>\n      <td>Motown, WV</td>\n      <td>So in one episode they undo season 1. Kai join...</td>\n      <td>[one, episode, undo, season, 1, kai, joins, ff...</td>\n      <td>[one, episode, undo, season, 1, kai, join, ff,...</td>\n      <td>one episode undo season 1 kai join ff ren beat...</td>\n    </tr>\n    <tr>\n      <th>846</th>\n      <td>2779</td>\n      <td>curfew</td>\n      <td>770 to Benedict College</td>\n      <td>everybody like fuck curfew.. and i'm sitting h...</td>\n      <td>[everybody, like, fuck, curfew, sitting, like,...</td>\n      <td>[everybody, like, fuck, curfew, sitting, like,...</td>\n      <td>everybody like fuck curfew sitting like bed 12</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>2897</td>\n      <td>damage</td>\n      <td>California, USA</td>\n      <td>Got my first damage today  fuckkkkkk</td>\n      <td>[got, first, damage, today, fuckkkkkk]</td>\n      <td>[got, first, damage, today, fuckkkkkk]</td>\n      <td>got first damage today fuckkkkkk</td>\n    </tr>\n    <tr>\n      <th>1018</th>\n      <td>3348</td>\n      <td>demolished</td>\n      <td>Connecticut</td>\n      <td>That ball was fucking demolished</td>\n      <td>[ball, fucking, demolished]</td>\n      <td>[ball, fucking, demolished]</td>\n      <td>ball fucking demolished</td>\n    </tr>\n    <tr>\n      <th>1020</th>\n      <td>3350</td>\n      <td>demolished</td>\n      <td>NaN</td>\n      <td>@who_mikejoness I hate seeing the boy get fuck...</td>\n      <td>[mikejoness, hate, seeing, boy, get, fucking, ...</td>\n      <td>[mikejoness, hate, seeing, boy, get, fucking, ...</td>\n      <td>mikejoness hate seeing boy get fucking demolis...</td>\n    </tr>\n    <tr>\n      <th>1432</th>\n      <td>4743</td>\n      <td>evacuate</td>\n      <td>San Diego</td>\n      <td>my father fucking died when the north tower co...</td>\n      <td>[father, fucking, died, north, tower, collapse...</td>\n      <td>[father, fucking, died, north, tower, collapse...</td>\n      <td>father fucking died north tower collapsed tryi...</td>\n    </tr>\n    <tr>\n      <th>1451</th>\n      <td>4815</td>\n      <td>evacuation</td>\n      <td>NaN</td>\n      <td>my school is so fucking dumb they just set off...</td>\n      <td>[school, fucking, dumb, set, evacuation, siren...</td>\n      <td>[school, fucking, dumb, set, evacuation, siren...</td>\n      <td>school fucking dumb set evacuation siren accident</td>\n    </tr>\n    <tr>\n      <th>1482</th>\n      <td>4932</td>\n      <td>exploded</td>\n      <td>NaN</td>\n      <td>Our electricity just fucking exploded they're ...</td>\n      <td>[electricity, fucking, exploded, trying, fix]</td>\n      <td>[electricity, fucking, exploded, trying, fix]</td>\n      <td>electricity fucking exploded trying fix</td>\n    </tr>\n    <tr>\n      <th>1576</th>\n      <td>5318</td>\n      <td>fire</td>\n      <td>NaN</td>\n      <td>almost set the house on fire tryna make fuckin...</td>\n      <td>[almost, set, house, fire, tryna, make, fuckin...</td>\n      <td>[almost, set, house, fire, tryna, make, fuckin...</td>\n      <td>almost set house fire tryna make fucking hotdog</td>\n    </tr>\n    <tr>\n      <th>1629</th>\n      <td>5483</td>\n      <td>flames</td>\n      <td>Little Rock</td>\n      <td>I only fuck you when it's half past five</td>\n      <td>[fuck, half, past, five]</td>\n      <td>[fuck, half, past, five]</td>\n      <td>fuck half past five</td>\n    </tr>\n    <tr>\n      <th>1804</th>\n      <td>6095</td>\n      <td>hellfire</td>\n      <td>NaN</td>\n      <td>I'm melting a bar of chocolate under my laptop...</td>\n      <td>[melting, bar, chocolate, laptop, least, fucki...</td>\n      <td>[melting, bar, chocolate, laptop, least, fucki...</td>\n      <td>melting bar chocolate laptop least fucking hel...</td>\n    </tr>\n    <tr>\n      <th>2190</th>\n      <td>7333</td>\n      <td>nuclear%20reactor</td>\n      <td>NaN</td>\n      <td>they're gonna fucking steal a nuclear fission ...</td>\n      <td>[gonna, fucking, steal, nuclear, fission, reac...</td>\n      <td>[gonna, fucking, steal, nuclear, fission, reac...</td>\n      <td>gonna fucking steal nuclear fission reactor</td>\n    </tr>\n    <tr>\n      <th>2552</th>\n      <td>8521</td>\n      <td>screaming</td>\n      <td>HYPE RESSHA HYPE RESSHA</td>\n      <td>i'm fucking screaming http://t.co/H3MrqRrGfe</td>\n      <td>[fucking, screaming]</td>\n      <td>[fucking, screaming]</td>\n      <td>fucking screaming</td>\n    </tr>\n    <tr>\n      <th>2956</th>\n      <td>9793</td>\n      <td>trapped</td>\n      <td>Houston, TX</td>\n      <td>If I ever saw a dog trapped in a hot car you b...</td>\n      <td>[ever, saw, dog, trapped, hot, car, better, be...</td>\n      <td>[ever, saw, dog, trapped, hot, car, better, be...</td>\n      <td>ever saw dog trapped hot car better believe bu...</td>\n    </tr>\n    <tr>\n      <th>2961</th>\n      <td>9804</td>\n      <td>trapped</td>\n      <td>Orlando</td>\n      <td>It's a trap not a fucking game. U ain't trappi...</td>\n      <td>[trap, fucking, game, u, trapping, u, trapped]</td>\n      <td>[trap, fucking, game, u, trapping, u, trapped]</td>\n      <td>trap fucking game u trapping u trapped</td>\n    </tr>\n    <tr>\n      <th>3018</th>\n      <td>9966</td>\n      <td>tsunami</td>\n      <td>rest easy angel @datboiiharri.</td>\n      <td>I just wanna food but of course I had to get c...</td>\n      <td>[wanna, food, course, get, caught, fucking, ts...</td>\n      <td>[wanna, food, course, get, caught, fucking, ts...</td>\n      <td>wanna food course get caught fucking tsunami</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.text.str.find('fuck') > 0] # we will use these explicit words to add an additional column to our dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This useful package will be used to check the probability of profanity in our text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from profanity_check import predict, predict_prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predict_prob(['go to hell, you scum'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## That was some basic cleaning, lemmatizing, and tokenizing: Now let us try to prepare our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(test.text_str)\n",
    "\n",
    "# Printing the identified Unique words along with their indices\n",
    "print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "\n",
    "# Encode the Document\n",
    "X_varied = vectorizer.transform(test.text_str)\n",
    "\n",
    "# Summarizing the Encoded Texts\n",
    "print(\"Encoded Document is:\")\n",
    "print(X_varied.toarray())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_varied = test[['target']]\n",
    "\n",
    "# logistic regression\n",
    "logit_clf = LogisticRegression()\n",
    "logit_clf.fit(X_varied, y_varied)\n",
    "y_logit = logit_clf.predict(X_varied)\n",
    "\n",
    "# svm\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_varied, y_varied)\n",
    "y_svm = svm_clf.predict(X_varied)\n",
    "\n",
    "\n",
    "# scoring (naive, not cross-validated)\n",
    "print(f\"Logit score: {logit_clf.score(X_varied, y_varied):.3f}\")\n",
    "print(f\"SVM score:   {svm_clf.score(X_varied, y_varied):.3f}\")\n",
    "\n",
    "# scoring (with cross validation)\n",
    "print(f\"Logit score, cross validated: {np.mean(cross_val_score(logit_clf, X_varied, y_varied)):.3f}\")\n",
    "print(f\"SVM score, cross validated:   {np.mean(cross_val_score(svm_clf, X_varied, y_varied)):.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for n in range(1,10):\n",
    "#     #knn\n",
    "#     print(f\"Number of clusters is {n}\")\n",
    "#     knn_clf = KNeighborsClassifier(n_neighbors=n) # instantiate\n",
    "#     knn_clf.fit(X_varied, y_varied)               # fit\n",
    "#     y_knn = knn_clf.predict(X_varied)             # predict\n",
    "#\n",
    "#     #scoring (naive, not cross-validated)\n",
    "#     print(f\"kNN score:   {knn_clf.score(X_varied, y_varied):.3f}\")\n",
    "#\n",
    "#     #scoring (with cross validation)\n",
    "#     print(f\"kNN score, cross validated:   {np.mean(cross_val_score(knn_clf, X_varied, y_varied)):.3f}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now that we have used a count vectorizer to transformn our cornpus let us try to use a TF-ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_varied = vectorizer.fit_transform(test.text_str)\n",
    "\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "print(X_varied.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_varied = test[['target']]\n",
    "\n",
    "# logistic regression\n",
    "logit_clf = LogisticRegression()\n",
    "logit_clf.fit(X_varied, y_varied)\n",
    "y_logit = logit_clf.predict(X_varied)\n",
    "\n",
    "# svm\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_varied, y_varied)\n",
    "y_svm = svm_clf.predict(X_varied)\n",
    "\n",
    "# scoring (naive, not cross-validated)\n",
    "print(f\"Logit score: {logit_clf.score(X_varied, y_varied):.3f}\")\n",
    "print(f\"SVM score:   {svm_clf.score(X_varied, y_varied):.3f}\")\n",
    "\n",
    "# scoring (with cross validation)\n",
    "print(f\"Logit score, cross validated: {np.mean(cross_val_score(logit_clf, X_varied, y_varied)):.3f}\")\n",
    "print(f\"SVM score, cross validated:   {np.mean(cross_val_score(svm_clf, X_varied, y_varied)):.3f}\\n\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for n in range(7, 15): # it seens like 11 is the best score for our model\n",
    "#     #knn\n",
    "#     print(f\"Number of clusters is {n}\")\n",
    "#     knn_clf = KNeighborsClassifier(n_neighbors=n)  # instantiate\n",
    "#     knn_clf.fit(X_varied, y_varied)  # fit\n",
    "#     y_knn = knn_clf.predict(X_varied)  # predict\n",
    "#\n",
    "#     #scoring (naive, not cross-validated)\n",
    "#     print(f\"kNN score:   {knn_clf.score(X_varied, y_varied):.3f}\")\n",
    "#\n",
    "#     #scoring (with cross validation)\n",
    "#     print(f\"kNN score, cross validated:   {np.mean(cross_val_score(knn_clf, X_varied, y_varied)):.3f}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'kNN': KNeighborsClassifier(n_neighbors = 11),\n",
    "    'Logit':LogisticRegression(),\n",
    "    'Tree': DecisionTreeClassifier(),\n",
    "    'Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "scores1 = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers:\n",
    "    scores1[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        X_varied, # feature matrix\n",
    "        y_varied, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy', 'recall', 'f1'] # scoring methods\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lets try the same approach but without removing stopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['text_lower'] = train.text.apply(lambda x: x.lower())\n",
    "test['text_lower'] = test.text.apply(lambda x: x.lower())\n",
    "test.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer.fit(test['text_lower'])\n",
    "X = vectorizer.transform(test['text_lower'])\n",
    "y =  test[[\"target\"]]\n",
    "\n",
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'kNN': KNeighborsClassifier(n_neighbors = 11),\n",
    "    'Logit':LogisticRegression(),\n",
    "    'Tree': DecisionTreeClassifier(),\n",
    "    'Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "scores2 = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers:\n",
    "    scores2[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        X, # feature matrix\n",
    "        y, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy', 'recall', 'f1'] # scoring methods\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Examine the performance of our simple classifiers\n",
    "\n",
    "def compare_scores(scores_dict):\n",
    "    '''\n",
    "    Takes a dictionary of cross_validate scores.\n",
    "    Returns a color-coded Pandas dataframe that summarizes those scores.\n",
    "    '''\n",
    "    df = pd.DataFrame(scores_dict).T.applymap(np.mean).style.background_gradient(cmap='RdYlGn')\n",
    "    return df\n",
    "# Compare cross-validation scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_scores(scores1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_scores(scores2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time for a different apporach. Word Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#nlp = gensim_api.load(\"word2vec-google-news-300\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "corpus = train[\"text\"]\n",
    "\n",
    "## create list of lists of unigrams\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1])\n",
    "                 for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)\n",
    "\n",
    "## detect bigrams and trigrams\n",
    "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus,\n",
    "                                                 delimiter=\" \".encode(), min_count=5, threshold=10)\n",
    "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
    "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus],\n",
    "                                                  delimiter=\" \".encode(), min_count=5, threshold=10)\n",
    "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
