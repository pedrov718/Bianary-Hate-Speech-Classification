{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Beginning Work on Twitter Disaster Kaggle Competition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing as preproc\n",
    "from sklearn.feature_extraction import text\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we will define a function that takes in a column with raw text data and returns a cleaned version of that column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\\\data\\\\test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Things to notice is that the size of our dataframe is 3263 but there are only 3237 non-null values and 2158 for keyword and location respectively"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n       'fire', 'fire%20truck', 'first%20responders', 'flames',\n       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keyword.unique() # notice NaN is a keyword"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([nan, 'London', \"Niall's place | SAF 12 SQUAD |\", ...,\n       'Acey mountain islanddåÇTorontoåÈ', 'los angeles',\n       'Brussels, Belgium'], dtype=object)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location.unique() # again here NaN is a location"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eventually we will need to figure out what to do with these missing values, but for now lets focus on cleaning up the text!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([    0,     2,     3, ..., 10868, 10874, 10875], dtype=int64)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id.unique() # no repeating ids which is good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'keyword', 'location', 'text'], dtype='object')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Found a list of contractions from a stack overflow post. This dictionary will be used to convert contractions to their root words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = {\n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This function will be used to do 4 things at once:\n",
    " 1) it will turn any contractions that appear above into their respected root words i.e \"won't\" will become \"will not\"\n",
    "2) It will use a regular expression to remove any unwanted characters from our text. In this case unwanted characters are punctuation and any special characters sucha as '@'\n",
    "3) It will remove any stop words that appear in our text. Here the stop words were pulled from a pre-defined list of stopwords from NLTK\n",
    "4) Lastly it will tokenize our text. Tokenization is the process of taking a body of text and converting it into lists of strings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "\n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace contractions with their longer forms\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\")) # pulling a list of stopwords from NLTK\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df['text_cleaned'] = list(map(clean_text, df.text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lemmatizing is the process of taking a word like swimming and converting it to its dictionary root word. So swimming becomes swim, eating becomes eat. Swam becomes swim. For more information click here:\n",
    "https://towardsdatascience.com/lemmatization-in-natural-language-processing-nlp-and-machine-learning-a4416f69a7b6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def lemmatized_words(text):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    df['lemmatized_text'] = list(map(lambda word:\n",
    "                                     list(map(lemm.lemmatize, word)),\n",
    "                                     df.text_cleaned))\n",
    "\n",
    "lemmatized_words(df.text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   0     NaN      NaN                 Just happened a terrible car crash   \n1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n\n                                        text_cleaned  \\\n0                   [happened, terrible, car, crash]   \n1  [heard, earthquake, different, cities, stay, s...   \n2  [forest, fire, spot, pond, geese, fleeing, acr...   \n3         [apocalypse, lighting, spokane, wildfires]   \n4      [typhoon, soudelor, kills, 28, china, taiwan]   \n\n                                     lemmatized_text  \n0                   [happened, terrible, car, crash]  \n1  [heard, earthquake, different, city, stay, saf...  \n2  [forest, fire, spot, pond, goose, fleeing, acr...  \n3          [apocalypse, lighting, spokane, wildfire]  \n4       [typhoon, soudelor, kill, 28, china, taiwan]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>text_cleaned</th>\n      <th>lemmatized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n      <td>[happened, terrible, car, crash]</td>\n      <td>[happened, terrible, car, crash]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n      <td>[heard, earthquake, different, cities, stay, s...</td>\n      <td>[heard, earthquake, different, city, stay, saf...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n      <td>[forest, fire, spot, pond, geese, fleeing, acr...</td>\n      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n      <td>[apocalypse, lighting, spokane, wildfires]</td>\n      <td>[apocalypse, lighting, spokane, wildfire]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n      <td>[typhoon, soudelor, kills, 28, china, taiwan]</td>\n      <td>[typhoon, soudelor, kill, 28, china, taiwan]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
