{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning twitter data to be used to predict the probability of profanity!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:25.072696Z",
     "iopub.execute_input": "2022-10-03T19:11:25.073319Z",
     "iopub.status.idle": "2022-10-03T19:11:25.081362Z",
     "shell.execute_reply.started": "2022-10-03T19:11:25.073270Z",
     "shell.execute_reply": "2022-10-03T19:11:25.079893Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets = pd.read_csv(\"../data/hate-speech-and-offensive-language.csv\", index_col = \"Unnamed: 0\" )"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:25.086284Z",
     "iopub.execute_input": "2022-10-03T19:11:25.088011Z",
     "iopub.status.idle": "2022-10-03T19:11:25.165909Z",
     "shell.execute_reply.started": "2022-10-03T19:11:25.087948Z",
     "shell.execute_reply": "2022-10-03T19:11:25.164311Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:25.168049Z",
     "iopub.execute_input": "2022-10-03T19:11:25.168455Z",
     "iopub.status.idle": "2022-10-03T19:11:25.189803Z",
     "shell.execute_reply.started": "2022-10-03T19:11:25.168420Z",
     "shell.execute_reply": "2022-10-03T19:11:25.187877Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       count  hate_speech  offensive_language  neither  class  \\\n0          3            0                   0        3      2   \n1          3            0                   3        0      1   \n2          3            0                   3        0      1   \n3          3            0                   2        1      1   \n4          6            0                   6        0      1   \n...      ...          ...                 ...      ...    ...   \n25291      3            0                   2        1      1   \n25292      3            0                   1        2      2   \n25294      3            0                   3        0      1   \n25295      6            0                   6        0      1   \n25296      3            0                   0        3      2   \n\n                                                   tweet  \n0      !!! RT @mayasolovely: As a woman you shouldn't...  \n1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n...                                                  ...  \n25291  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n25292  you've gone and broke the wrong heart baby, an...  \n25294  young buck wanna eat!!.. dat nigguh like I ain...  \n25295              youu got wild bitches tellin you lies  \n25296  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n\n[24783 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>hate_speech</th>\n      <th>offensive_language</th>\n      <th>neither</th>\n      <th>class</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25291</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n    </tr>\n    <tr>\n      <th>25292</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>you've gone and broke the wrong heart baby, an...</td>\n    </tr>\n    <tr>\n      <th>25294</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n    </tr>\n    <tr>\n      <th>25295</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>youu got wild bitches tellin you lies</td>\n    </tr>\n    <tr>\n      <th>25296</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24783 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there had\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:25.192609Z",
     "iopub.execute_input": "2022-10-03T19:11:25.193168Z",
     "iopub.status.idle": "2022-10-03T19:11:25.214996Z",
     "shell.execute_reply.started": "2022-10-03T19:11:25.193116Z",
     "shell.execute_reply": "2022-10-03T19:11:25.212975Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_text_from_tweet(text, remove_stopwords = False):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "\n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # removing non-ascii characters\n",
    "    new_val = text.encode(\"ascii\", \"ignore\")\n",
    "    text = new_val.decode()\n",
    "\n",
    "    # Replace contractions with their longer forms\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) # removes website links\n",
    "    text = re.sub(r'\\<a href', ' ', text) # removed HTML tags\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:$\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "\n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\")) # pulli-ng a list of stopwords from NLTK\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:25.218876Z",
     "iopub.execute_input": "2022-10-03T19:11:25.219509Z",
     "iopub.status.idle": "2022-10-03T19:11:25.240893Z",
     "shell.execute_reply.started": "2022-10-03T19:11:25.219444Z",
     "shell.execute_reply": "2022-10-03T19:11:25.238671Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets[\"clean_tweet\"] = tweets[\"tweet\"].apply(clean_text_from_tweet)\n",
    "tweets[\"clean_tweet_string\"] = tweets[\"clean_tweet\"].apply(lambda x: \" \".join(x) )"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:25.244090Z",
     "iopub.execute_input": "2022-10-03T19:11:25.244697Z",
     "iopub.status.idle": "2022-10-03T19:11:26.054919Z",
     "shell.execute_reply.started": "2022-10-03T19:11:25.244637Z",
     "shell.execute_reply": "2022-10-03T19:11:26.053269Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:26.057171Z",
     "iopub.execute_input": "2022-10-03T19:11:26.057586Z",
     "iopub.status.idle": "2022-10-03T19:11:26.087649Z",
     "shell.execute_reply.started": "2022-10-03T19:11:26.057551Z",
     "shell.execute_reply": "2022-10-03T19:11:26.085238Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       count  hate_speech  offensive_language  neither  class  \\\n0          3            0                   0        3      2   \n1          3            0                   3        0      1   \n2          3            0                   3        0      1   \n3          3            0                   2        1      1   \n4          6            0                   6        0      1   \n...      ...          ...                 ...      ...    ...   \n25291      3            0                   2        1      1   \n25292      3            0                   1        2      2   \n25294      3            0                   3        0      1   \n25295      6            0                   6        0      1   \n25296      3            0                   0        3      2   \n\n                                                   tweet  \\\n0      !!! RT @mayasolovely: As a woman you shouldn't...   \n1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n...                                                  ...   \n25291  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n25292  you've gone and broke the wrong heart baby, an...   \n25294  young buck wanna eat!!.. dat nigguh like I ain...   \n25295              youu got wild bitches tellin you lies   \n25296  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n\n                                             clean_tweet  \\\n0      [rt, as, a, woman, you, should, not, complain,...   \n1      [rt, boy, dats, cold, tyga, dwn, bad, for, cuf...   \n2      [rt, dawg, rt, you, ever, fuck, a, bitch, and,...   \n3      [rt, g, anderson, based, she, look, like, a, t...   \n4      [rt, the, shit, you, hear, about, me, might, b...   \n...                                                  ...   \n25291  [you, s, a, muthaf, in, lie, pearls, emanuel, ...   \n25292  [you, ve, gone, and, broke, the, wrong, heart,...   \n25294  [young, buck, wanna, eat, dat, nigguh, like, i...   \n25295      [youu, got, wild, bitches, tellin, you, lies]   \n25296  [~~, ruffled, ntac, eileen, dahlia, beautiful,...   \n\n                                      clean_tweet_string  \n0      rt as a woman you should not complain about cl...  \n1      rt boy dats cold tyga dwn bad for cuffin dat h...  \n2      rt dawg rt you ever fuck a bitch and she start...  \n3             rt g anderson based she look like a tranny  \n4      rt the shit you hear about me might be true or...  \n...                                                  ...  \n25291  you s a muthaf in lie pearls emanuel right his...  \n25292  you ve gone and broke the wrong heart baby and...  \n25294  young buck wanna eat dat nigguh like i aint fu...  \n25295              youu got wild bitches tellin you lies  \n25296  ~~ ruffled ntac eileen dahlia beautiful color ...  \n\n[24783 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>hate_speech</th>\n      <th>offensive_language</th>\n      <th>neither</th>\n      <th>class</th>\n      <th>tweet</th>\n      <th>clean_tweet</th>\n      <th>clean_tweet_string</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n      <td>[rt, as, a, woman, you, should, not, complain,...</td>\n      <td>rt as a woman you should not complain about cl...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n      <td>[rt, boy, dats, cold, tyga, dwn, bad, for, cuf...</td>\n      <td>rt boy dats cold tyga dwn bad for cuffin dat h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n      <td>[rt, dawg, rt, you, ever, fuck, a, bitch, and,...</td>\n      <td>rt dawg rt you ever fuck a bitch and she start...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n      <td>[rt, g, anderson, based, she, look, like, a, t...</td>\n      <td>rt g anderson based she look like a tranny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n      <td>[rt, the, shit, you, hear, about, me, might, b...</td>\n      <td>rt the shit you hear about me might be true or...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25291</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n      <td>[you, s, a, muthaf, in, lie, pearls, emanuel, ...</td>\n      <td>you s a muthaf in lie pearls emanuel right his...</td>\n    </tr>\n    <tr>\n      <th>25292</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>you've gone and broke the wrong heart baby, an...</td>\n      <td>[you, ve, gone, and, broke, the, wrong, heart,...</td>\n      <td>you ve gone and broke the wrong heart baby and...</td>\n    </tr>\n    <tr>\n      <th>25294</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n      <td>[young, buck, wanna, eat, dat, nigguh, like, i...</td>\n      <td>young buck wanna eat dat nigguh like i aint fu...</td>\n    </tr>\n    <tr>\n      <th>25295</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>youu got wild bitches tellin you lies</td>\n      <td>[youu, got, wild, bitches, tellin, you, lies]</td>\n      <td>youu got wild bitches tellin you lies</td>\n    </tr>\n    <tr>\n      <th>25296</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n      <td>[~~, ruffled, ntac, eileen, dahlia, beautiful,...</td>\n      <td>~~ ruffled ntac eileen dahlia beautiful color ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24783 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tweets['class'].value_counts(normalize= True)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:26.091628Z",
     "iopub.execute_input": "2022-10-03T19:11:26.092135Z",
     "iopub.status.idle": "2022-10-03T19:11:26.106483Z",
     "shell.execute_reply.started": "2022-10-03T19:11:26.092096Z",
     "shell.execute_reply": "2022-10-03T19:11:26.104529Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "1    0.774321\n2    0.167978\n0    0.057701\nName: class, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tweets_offensive_language = tweets.loc[(tweets['class'] == 1) | (tweets['class'] == 2)]"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:26.108692Z",
     "iopub.execute_input": "2022-10-03T19:11:26.109143Z",
     "iopub.status.idle": "2022-10-03T19:11:26.132252Z",
     "shell.execute_reply.started": "2022-10-03T19:11:26.109106Z",
     "shell.execute_reply": "2022-10-03T19:11:26.130482Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets_offensive_language[\"class\"].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:11:26.133919Z",
     "iopub.execute_input": "2022-10-03T19:11:26.134462Z",
     "iopub.status.idle": "2022-10-03T19:11:26.148478Z",
     "shell.execute_reply.started": "2022-10-03T19:11:26.134424Z",
     "shell.execute_reply": "2022-10-03T19:11:26.146861Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "1    0.821736\n2    0.178264\nName: class, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lets try spacy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from spacymoji import Emoji\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T19:29:55.483959Z",
     "iopub.execute_input": "2022-10-03T19:29:55.485168Z",
     "iopub.status.idle": "2022-10-03T19:29:55.492479Z",
     "shell.execute_reply.started": "2022-10-03T19:29:55.485057Z",
     "shell.execute_reply": "2022-10-03T19:29:55.491035Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.add_pipe(\"emoji\", first=True)\n",
    "# doc = nlp(\"This is a test 😻 👍🏿\")\n",
    "#\n",
    "# assert doc._.has_emoji is True\n",
    "# assert doc[2:5]._.has_emoji is True\n",
    "# assert doc[0]._.is_emoji is False\n",
    "# assert doc[4]._.is_emoji is True\n",
    "# assert doc[5]._.emoji_desc == \"thumbs up dark skin tone\"\n",
    "# assert len(doc._.emoji) == 2\n",
    "# assert doc._.emoji[1] == (\"👍🏿\", 5, \"thumbs up dark skin tone\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loadint the spacy package and writing a custom preporcessing class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 nlp = nlp,\n",
    "                 n_jobs=1):\n",
    "        \"\"\"\n",
    "        Text preprocessing transformer includes steps:\n",
    "            1. Punctuation removal\n",
    "            2. Stop words removal\n",
    "            3. Removing handles/usernames\n",
    "            4. Lemmatization\n",
    "\n",
    "        nlp  - spacy model\n",
    "        n_jobs - parallel jobs to run\n",
    "        \"\"\"\n",
    "        self.nlp = nlp\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, *_):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        partitions = 1\n",
    "        cores = mp.cpu_count()\n",
    "        if self.n_jobs <= -1:\n",
    "            partitions = cores\n",
    "        elif self.n_jobs <= 0:\n",
    "            return X_copy.apply(self._preprocess_text)\n",
    "        else:\n",
    "            partitions = min(self.n_jobs, cores)\n",
    "\n",
    "        data_split = np.array_split(X_copy, partitions)\n",
    "        pool = mp.Pool(cores)\n",
    "        data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _preprocess_part(self, part):\n",
    "        return part.apply(self._preprocess_text)\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        replace_emoji = self._replace_emoji(doc)\n",
    "        doc = nlp(replace_emoji)\n",
    "\n",
    "        removed_punct = self._remove_punct(doc)\n",
    "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
    "        removed_user_names = self._remove_user_names(removed_stop_words)\n",
    "        removed_links = self._remove_links(removed_user_names)\n",
    "        return self._lemmatize(removed_links)\n",
    "\n",
    "    def _normalize(self, text):\n",
    "        # some issues in normalise package\n",
    "        try:\n",
    "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
    "        except:\n",
    "            return text\n",
    "\n",
    "    def _replace_emoji(self, doc):\n",
    "        text = ''\n",
    "        for t in doc:\n",
    "            if t._.is_emoji:\n",
    "                text += str(t._.emoji_desc) + ' '\n",
    "            else:\n",
    "                text +=  str(t) + ' '\n",
    "        return text\n",
    "\n",
    "    def _remove_punct(self, doc):\n",
    "        return (t for t in doc if t.text not in string.punctuation)\n",
    "\n",
    "    def _remove_stop_words(self, doc):\n",
    "        return (t for t in doc if not t.is_stop)\n",
    "\n",
    "    def _remove_user_names(self, doc):\n",
    "        return (t for t in doc if '@' not in t.text)\n",
    "\n",
    "    def _remove_links(self,doc):\n",
    "        return (t for t in doc if not t.like_url)\n",
    "\n",
    "    def _lemmatize(self, doc):\n",
    "        return ' '.join(t.lemma_ for t in doc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = TextPreprocessor(n_jobs=-1).transform(tweets[\"tweet\"][:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import  LogisticRegressionCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics.pairwise import normalize\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.svm import LinearSVC\n",
    "#\n",
    "# X = tweets_offensive_language[\"tweet\"][:100]\n",
    "# y = tweets_offensive_language[\"class\"][:100]\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 42, test_size= .3, stratify= y)\n",
    "#\n",
    "# clf  = Pipeline(steps=[\n",
    "#     ('normalize', TextPreprocessor(n_jobs=-1)),\n",
    "#     ('features', TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True))\n",
    "# ])\n",
    "#\n",
    "#\n",
    "# clf.fit(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-10-03T20:13:31.589722Z",
     "iopub.execute_input": "2022-10-03T20:13:31.590216Z",
     "iopub.status.idle": "2022-10-03T20:13:34.726688Z",
     "shell.execute_reply.started": "2022-10-03T20:13:31.590157Z",
     "shell.execute_reply": "2022-10-03T20:13:34.725266Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
