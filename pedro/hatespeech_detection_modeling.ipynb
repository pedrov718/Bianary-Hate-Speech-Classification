{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing our cleaned dataset from our EDA notebook"
      ],
      "metadata": {
        "id": "7dkSWjzOpOET"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QOV0t39UpPxQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/hatespeech_detection/binary_hatespeech_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary modeling packages\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score, classification_report, plot_confusion_matrix, plot_roc_curve, roc_auc_score, recall_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics.pairwise import normalize\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBClassifier\n",
        "!pip install datasets\n",
        "import datasets\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "KZn-J_C-GRwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f1e141-9a69-49d0-b333-990b10726734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (5.0.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets define a custom crossvalidation function that we can use with our pipeline object."
      ],
      "metadata": {
        "id": "j4chHCYrvCLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation_pip(X_train, y_train, estimator, num_split = 5):\n",
        "  \n",
        "  kf = KFold(n_splits= num_split)\n",
        "\n",
        "  kf.get_n_splits(X_train)\n",
        "  \n",
        "  score_val_list = []\n",
        "  score_train_list = []\n",
        "  \n",
        "  for train_index, test_index in kf.split(X):\n",
        "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "      estimator.fit(X_train, y_train)\n",
        "      y_pred_train = estimator.predict(X_train)\n",
        "      y_pred_test = estimator.predict(X_test)\n",
        "\n",
        "      #recall_score(y_test, y_pred_best)\n",
        "      # now how did we do?\n",
        "      recall_train = recall_score(y_train, y_pred_train)\n",
        "      recall_val = recall_score(y_test, y_pred_test)\n",
        "      score_val_list.append(recall_val)\n",
        "      score_train_list.append(recall_train)\n",
        "    \n",
        "  return {'train': np.mean(score_train_list), 'validation': np.mean(score_val_list)}"
      ],
      "metadata": {
        "id": "MJ1lXTBLvA06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our baseline model will be a simple logistic regression model"
      ],
      "metadata": {
        "id": "MDmERGoto-XJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text_from_lemma'] # will be using our cleaned lemmatized words\n",
        "y = df['hatespeech'] # we will be doing a simple binary classifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 42, test_size= .3, stratify= y) # spliting our data and stratafying on y"
      ],
      "metadata": {
        "id": "s6W6c21xF5bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic = Pipeline(steps=[ \n",
        "        ('features', TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)),\n",
        "        ('classifier', LogisticRegression(solver='saga', n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "logistic.fit(X_train, y_train)\n",
        "\n",
        "y_pred_log = logistic.predict(X_test)\n",
        "\n",
        "y_pred_log_proba = logistic.predict_proba(X_test)\n",
        "\n",
        "logistic_score = cross_validation_pip(X_train, y_train, logistic, num_split = 3)"
      ],
      "metadata": {
        "id": "2qQ1HFsYobAF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUihcIdL0ba3",
        "outputId": "5043f9b3-f565-44a3-e963-cb0aea7fb135"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84     24187\n",
            "           1       0.80      0.70      0.75     16480\n",
            "\n",
            "    accuracy                           0.81     40667\n",
            "   macro avg       0.81      0.79      0.79     40667\n",
            "weighted avg       0.81      0.81      0.80     40667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(logistic, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "5W0Nemdr0d13",
        "outputId": "66e6d2d8-881e-4719-eff2-7082762ac92e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f78dcfbd650>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# search thresholds for imbalanced classification\n",
        "from numpy import arange\n",
        "from numpy import argmax\n",
        " \n",
        "# apply threshold to positive probabilities to create labels\n",
        "def to_labels(pos_probs, threshold):\n",
        "\treturn (pos_probs >= threshold).astype('int')\n",
        "\n",
        "# keep probabilities for the positive outcome only\n",
        "probs = y_pred_log_proba[:, 1]\n",
        "\n",
        "# define thresholds\n",
        "thresholds = arange(0, 1, 0.001)\n",
        "\n",
        "# evaluate each threshold\n",
        "scores = [f1_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
        "\n",
        "# get best threshold\n",
        "ix = argmax(scores)\n",
        "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))"
      ],
      "metadata": {
        "id": "KgdErNUbAdVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'logistic_model.sav'\n",
        "pickle.dump(logistic, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "FjpmTdJU0sK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a linear SVM model on our cleaned corpus\n"
      ],
      "metadata": {
        "id": "TihWrBiQGIul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining parameter range\n",
        "param_grid = {'classifier__C': [0.01, 0.1, 1, 10, 100, 1000],\n",
        "              'classifier__tol': [1e-5, 1e-4, 1e-2, 1, 1e3],\n",
        "              'vectorizer__max_df': (0.25, 0.5, 0.75),\n",
        "              'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "              'vectorizer__norm' : ('l1', 'l2'),\n",
        "              'vectorizer__sublinear_tf' : (True, False)\n",
        "              } "
      ],
      "metadata": {
        "id": "jmF_nFBwx2nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a pipeline for our best model: if you are interested to see how I got here please look at my preliminary notebook\n",
        "# https://colab.research.google.com/drive/1-IVjUg7nxMCUqeanlInnXHqNn14wAWjS?usp=sharing\n",
        "\n",
        "pipe  = Pipeline(steps=[\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LinearSVC(max_iter=10000, random_state=42))\n",
        "    ]) "
      ],
      "metadata": {
        "id": "HCgt-Vd8sB47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_pipe = RandomizedSearchCV(pipe, param_grid, n_iter=5, scoring= 'recall', n_jobs= -1, refit=True, random_state=42, return_train_score=True)\n",
        "\n",
        "gs_pipe.fit(X_train, y_train)\n",
        "\n",
        "best_est = gs_pipe.best_estimator_"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E8GS8NZKy8rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_est.fit(X_train, y_train)\n",
        "\n",
        "y_pred_best= best_est.predict(X_test)\n",
        "\n",
        "y_proba =  best_est.decision_function(X_test)\n",
        "\n",
        "best_est_score = best_est.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "Y8-TfTCbGBDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation_pip(X_test, y_test, best_est, num_split = 5)"
      ],
      "metadata": {
        "id": "o1dSY7eVvQWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy score for the model cleaned by this function with grid search parameter-tuning is {best_est_score}\")"
      ],
      "metadata": {
        "id": "CL1mgRE1R7sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(best_est, X_test, y_test)"
      ],
      "metadata": {
        "id": "5BEVODboR_Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Recall Score for the linearSVC is: {recall_score(y_test, y_pred_best)}\")"
      ],
      "metadata": {
        "id": "OgkYl1j24PtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_best))"
      ],
      "metadata": {
        "id": "Rj0n9D6vR_md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now its time to finetune our decision threshold for our linear SVM model"
      ],
      "metadata": {
        "id": "f87MuUjeB_oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "#create precision recall curve\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(recall, precision, color='purple')\n",
        "\n",
        "#add axis labels to plot\n",
        "ax.set_title('Precision-Recall Curve')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_xlabel('Recall')\n",
        "\n",
        "#display plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rhUV8Me78GmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep probabilities for the positive outcome only\n",
        "probs = y_proba\n",
        "\n",
        "# define thresholds\n",
        "thresholds = arange(0, 1, 0.001)\n",
        "\n",
        "# evaluate each threshold\n",
        "scores = [f1_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
        "\n",
        "# get best threshold\n",
        "ix = argmax(scores)\n",
        "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))"
      ],
      "metadata": {
        "id": "bmxKAq3wCIJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_curve(best_est, X_test, y_test)"
      ],
      "metadata": {
        "id": "mkaMyTMOSFAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test, y_proba)"
      ],
      "metadata": {
        "id": "RrvcbRnlSFYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_est['classifier'].coef_,"
      ],
      "metadata": {
        "id": "MRgk4Rlz1_EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_coefficients(classifier, feature_names, top_features=20):\n",
        " coef = classifier.coef_.ravel()\n",
        " top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
        " top_negative_coefficients = np.argsort(coef)[:top_features]\n",
        " top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
        "\n",
        " # create plot\n",
        "\n",
        " fig, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
        "\n",
        " ax.set_facecolor('black') \n",
        "\n",
        "# ax.yaxis.grid(True, which='major')\n",
        " ax.yaxis.grid(True, which='major', linestyle='-')\n",
        " ax.xaxis.grid(True, linestyle='dashed')\n",
        "\n",
        " ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=20)\n",
        " \n",
        " ax.tick_params(axis='x', which='major', labelsize=20)\n",
        "\n",
        " colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
        " \n",
        " plt.barh(np.arange(2 * top_features), coef[top_coefficients], color=colors,align = 'edge' )\n",
        "\n",
        " feature_names = np.array(feature_names)\n",
        "\n",
        " plt.yticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=0, ha= 'right')\n",
        "\n",
        "\n",
        " plt.title(\"Highest Weighted Words for Hate Speech Classification\", fontsize=30) \n",
        "\n",
        " plt.show()\n",
        "\n",
        "cv = best_est['vectorizer']\n",
        "\n",
        "svm = best_est['classifier']\n",
        "\n",
        "plot_coefficients(svm, cv.get_feature_names())"
      ],
      "metadata": {
        "id": "QNJnwZyU1oSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names of each feature\n",
        "feature_names = best_est.named_steps[\"vectorizer\"].get_feature_names()"
      ],
      "metadata": {
        "id": "6S87M_io_6Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the coefficients of each feature\n",
        "coefs = best_est.named_steps[\"classifier\"].coef_.flatten()"
      ],
      "metadata": {
        "id": "6tzOnrEA_4Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Zip coefficients and names together and make a DataFrame\n",
        "zipped = zip(feature_names, coefs)\n",
        "\n",
        "df_coefs = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
        "\n",
        "# Sort the features by the absolute value of their coefficient\n",
        "df_coefs[\"abs_value\"] = df_coefs[\"value\"].apply(lambda x: abs(x))\n",
        "\n",
        "df_coefs[\"colors\"] = df_coefs[\"value\"].apply(lambda x: \"yellow\" if x > 0 else \"red\")\n",
        "\n",
        "df_coefs = df_coefs.sort_values(\"abs_value\", ascending=False)"
      ],
      "metadata": {
        "id": "leSe2X5D_pjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "\n",
        "sns.barplot(y =\"feature\",\n",
        "            x =\"value\",\n",
        "            data=df_coefs.head(20),\n",
        "           palette=df_coefs.head(20)[\"colors\"])\n",
        "\n",
        "\n",
        "ax.set_facecolor('black') \n",
        "\n",
        "# ax.yaxis.grid(True, which='major')\n",
        "ax.xaxis.grid(True, which='major')\n",
        "\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=20)\n",
        "\n",
        "ax.set_title(\"Top 20 Indicators for Hate speech\", fontsize=30)\n",
        "ax.set_ylabel(\"Feature Names\", fontsize=22)\n",
        "ax.set_xlabel(\"Feature Importance\", fontsize=22)"
      ],
      "metadata": {
        "id": "FRqWeXi1_2Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'linearSVC_model_best.sav'\n",
        "pickle.dump(best_est, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "X1uutsqgXbJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that we have a finetuned model, lets try visualizing the errors our model is making and see if we can learn anything from the models mistakes"
      ],
      "metadata": {
        "id": "PurLj2JEyEdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = X\n",
        "prediction = y_pred_best\n",
        "label = y\n",
        "wrong_predicitons = {}\n",
        "\n",
        "for input, prediction, label in zip(input, prediction, label):\n",
        "  if prediction != label:\n",
        "    wrong_predicitons[input] = [prediction, label]\n",
        "\n",
        "predicitons = pd.DataFrame.from_dict(wrong_predicitons, orient='index',\n",
        "  columns=['text', 'prediciton/true_label'] )\n"
      ],
      "metadata": {
        "id": "4-c6kPmUyCd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets try a tree based model: XGBoost has good results with text classification."
      ],
      "metadata": {
        "id": "MC_xcqxQ1yPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text_from_lemma'] # will be using our cleaned lemmatized words\n",
        "\n",
        "y = df['hatespeech'] # we will be doing a simple binary classifier\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 42, test_size= .3, stratify= y) # spliting our data and stratafying on y\n",
        "\n",
        "\n",
        "# fit model no training data\n",
        "\n",
        "pipe_boost = Pipeline(steps=[\n",
        "    ('vectorizer', TfidfVectorizer(ngram_range = (1, 2))),\n",
        "    ('classifier', XGBClassifier())]) \n",
        "\n",
        "\n",
        "\n",
        "pipe_boost.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "\n",
        "y_pred_boost = pipe_boost.predict(X_test)\n",
        "\n",
        "# evaluate predictions\n",
        "\n",
        "print(classification_report(y_test, y_pred_boost))"
      ],
      "metadata": {
        "id": "HYr9cMAk2BsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets try doing some hyper parameter tuning for our xgboost model"
      ],
      "metadata": {
        "id": "jMekbyVJFf5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'classifier__max_depth': [3,4, 5], 'classifier__learning_rate': [.1, .3, .5],\n",
        "          'classifier__gamma': [0,5,10], 'classifier__n_estimators': [50,100, 150] }\n",
        "\n",
        "\n",
        "boost = RandomizedSearchCV(pipe_boost, params, n_iter=5, scoring= 'recall', n_jobs= -1, refit=True, random_state=42, return_train_score=True)\n",
        "\n",
        "boost.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1uvZYL0fSElL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_boost = boost.best_estimator_\n",
        "\n",
        "best_boost.fit(X_train, y_train);\n",
        "\n",
        "y_pred = best_boost.predict(X_test)\n",
        "\n",
        "total_preds = best_boost.predict(X_train)"
      ],
      "metadata": {
        "id": "w6Jmy4vVSgY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(best_boost, X_test, y_test)"
      ],
      "metadata": {
        "id": "EmGZyzwfz5m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "rHXFohli0MUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing original datasets to append predicition column to"
      ],
      "metadata": {
        "id": "UMi6xnRoMjLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'xgboost_model_best.sav'\n",
        "pickle.dump(best_boost, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "3h2eemS6pjSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'binary')\n",
        "new_df = dataset['train'].to_pandas()"
      ],
      "metadata": {
        "id": "ypMVysO-K7Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a predicition column for our corpus"
      ],
      "metadata": {
        "id": "Lo8o4sEVK7jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "id": "q2WsQQTXKdS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['hatespeech'] = (new_df['hatespeech']).apply(lambda x: 1 if x > 0 else 0)"
      ],
      "metadata": {
        "id": "TrqQhYkBKrlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = joblib.load('/content/linearSVC_model_best.sav')"
      ],
      "metadata": {
        "id": "ziJHIlQEIUEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = new_df[['text']]\n",
        "\n",
        "y = new_df['hatespeech']"
      ],
      "metadata": {
        "id": "1_KGHgkXJxiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_score = loaded_model.predict(X)"
      ],
      "metadata": {
        "id": "RBO1kSGgJn65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_score.shape"
      ],
      "metadata": {
        "id": "ytruU8H9KJ3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['predicitions'] = predicted_score"
      ],
      "metadata": {
        "id": "8ls2BFGYKSyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df[['text', 'hatespeech', 'predicitions']]"
      ],
      "metadata": {
        "id": "uTGRAbPtLsRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a profanity list to check how much profanity is in our hatespeech lablled corpus"
      ],
      "metadata": {
        "id": "PjCKK1gkhQKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# opening the file in read mode\n",
        "my_file = open(\"/content/profanity_wordlist.txt\", \"r\")\n",
        "  \n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "  \n",
        "# replacing end of line('/n') with ' ' and\n",
        "# splitting the text it further when '.' is seen.\n",
        "data_into_list = data.replace('\\n', ',').split(\".\")\n",
        "\n",
        "# printing the data\n",
        "print(data_into_list)\n",
        "my_file.close()"
      ],
      "metadata": {
        "id": "C1LpwyBoy5Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profanity_list = data_into_list[0].split(',') "
      ],
      "metadata": {
        "id": "kYosq7coz0zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def pattern_searcher(search_str:str, search_list:str):\n",
        "\n",
        "    search_obj = re.search(search_list, search_str)\n",
        "\n",
        "    if search_obj :\n",
        "        return_str = search_str[search_obj.start(): search_obj.end()]\n",
        "    else:\n",
        "        return_str = 'NA'\n",
        "    return return_str"
      ],
      "metadata": {
        "id": "EKPdxeV16TWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '|'.join(profanity_list)\n",
        "\n",
        "new_df['profanity_present'] = new_df['text'].apply(lambda x: pattern_searcher(search_str=x, search_list=pattern))"
      ],
      "metadata": {
        "id": "wwkYp0Qh6XMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}